name: End-to-End Integration Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - e2e-only
          - performance-only
          - multi-tenant-only
          - ai-services-only

env:
  NODE_VERSION: '18'
  DATABASE_URL: postgresql://test_user:test_password@localhost:5432/riscura_test
  REDIS_URL: redis://localhost:6379
  NEXTAUTH_SECRET: test-secret-key-for-ci
  NEXTAUTH_URL: http://localhost:3000
  OPENAI_API_KEY: test-openai-key
  CLEANUP_TEST_DATA: true
  CI: true

jobs:
  # Setup and validation
  setup:
    name: Setup and Validation
    runs-on: ubuntu-latest
    outputs:
      cache-key: ${{ steps.cache-key.outputs.key }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Generate cache key
        id: cache-key
        run: echo "key=${{ runner.os }}-node-${{ hashFiles('package-lock.json') }}" >> $GITHUB_OUTPUT

      - name: Install dependencies
        run: npm ci

      - name: Type checking
        run: npm run type-check

      - name: Lint code
        run: npm run lint

      - name: Security audit
        run: npm audit --audit-level high

  # Database and infrastructure setup
  infrastructure:
    name: Setup Test Infrastructure
    runs-on: ubuntu-latest
    needs: setup
    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: riscura_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:6
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Setup database
        run: |
          npm run db:migrate:deploy
          npm run db:seed

      - name: Verify database connection
        run: npm run db:health

  # Unit and integration tests
  unit-integration-tests:
    name: Unit & Integration Tests
    runs-on: ubuntu-latest
    needs: [setup, infrastructure]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run unit tests
        run: npm run test:coverage

      - name: Run integration tests
        run: npm run test:integration

      - name: Upload coverage reports
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/lcov.info
          fail_ci_if_error: true

  # AI Services testing
  ai-services-tests:
    name: AI Services Integration Tests
    runs-on: ubuntu-latest
    needs: [setup, infrastructure]
    if: ${{ github.event.inputs.test_suite == 'all' || github.event.inputs.test_suite == 'ai-services-only' || github.event.inputs.test_suite == '' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run AI services integration tests
        run: npm run test:ai-services

      - name: Upload AI test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ai-services-test-results
          path: test-results/

  # End-to-End tests with Playwright
  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: [setup, infrastructure]
    if: ${{ github.event.inputs.test_suite == 'all' || github.event.inputs.test_suite == 'e2e-only' || github.event.inputs.test_suite == '' }}
    strategy:
      matrix:
        browser: [chromium, firefox]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install --with-deps ${{ matrix.browser }}

      - name: Start application
        run: |
          npm run build
          npm start &
          npx wait-on http://localhost:3000 --timeout 60000

      - name: Run E2E tests
        run: npx playwright test --project=${{ matrix.browser }}
        env:
          PLAYWRIGHT_BASE_URL: http://localhost:3000

      - name: Upload E2E test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-test-results-${{ matrix.browser }}
          path: |
            test-results/
            playwright-report/

  # Multi-tenant security tests
  multi-tenant-tests:
    name: Multi-Tenant Security Tests
    runs-on: ubuntu-latest
    needs: [setup, infrastructure]
    if: ${{ github.event.inputs.test_suite == 'all' || github.event.inputs.test_suite == 'multi-tenant-only' || github.event.inputs.test_suite == '' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install --with-deps chromium

      - name: Start application
        run: |
          npm run build
          npm start &
          npx wait-on http://localhost:3000 --timeout 60000

      - name: Run multi-tenant isolation tests
        run: npx playwright test --project=multi-tenant
        env:
          PLAYWRIGHT_BASE_URL: http://localhost:3000

      - name: Upload multi-tenant test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: multi-tenant-test-results
          path: test-results/

  # Performance and load tests
  performance-tests:
    name: Performance & Load Tests
    runs-on: ubuntu-latest
    needs: [setup, infrastructure]
    if: ${{ github.event.inputs.test_suite == 'all' || github.event.inputs.test_suite == 'performance-only' || github.event.inputs.test_suite == '' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install --with-deps chromium

      - name: Start application
        run: |
          npm run build
          npm start &
          npx wait-on http://localhost:3000 --timeout 60000

      - name: Run performance tests
        run: npx playwright test --project=performance
        env:
          PLAYWRIGHT_BASE_URL: http://localhost:3000

      - name: Generate performance report
        run: |
          echo "## Performance Test Results" >> $GITHUB_STEP_SUMMARY
          if [ -f test-results/performance-metrics.json ]; then
            node -e "
              const metrics = JSON.parse(require('fs').readFileSync('test-results/performance-metrics.json', 'utf8'));
              console.log('| Metric | Value | Status |');
              console.log('|--------|-------|--------|');
              console.log('| Average Response Time | ' + (metrics.averageResponseTime || 'N/A') + 'ms | ' + (metrics.averageResponseTime < 2000 ? 'âœ…' : 'âŒ') + ' |');
              console.log('| P95 Response Time | ' + (metrics.p95ResponseTime || 'N/A') + 'ms | ' + (metrics.p95ResponseTime < 5000 ? 'âœ…' : 'âŒ') + ' |');
              console.log('| Error Rate | ' + (metrics.errorRate || 'N/A') + '% | ' + (metrics.errorRate < 1 ? 'âœ…' : 'âŒ') + ' |');
              console.log('| Peak Memory Usage | ' + (metrics.peakMemoryUsage || 'N/A') + 'MB | ' + (metrics.peakMemoryUsage < 512 ? 'âœ…' : 'âŒ') + ' |');
            " >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload performance test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-test-results
          path: test-results/

  # Security testing
  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    needs: [setup, infrastructure]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run security checks
        run: npm run security:full

      - name: OWASP ZAP security scan
        uses: zaproxy/action-full-scan@v0.4.0
        with:
          target: 'http://localhost:3000'
          rules_file_name: '.zap/rules.tsv'
          cmd_options: '-a'
        continue-on-error: true

  # Deployment readiness check
  deployment-readiness:
    name: Deployment Readiness Check
    runs-on: ubuntu-latest
    needs: [unit-integration-tests, e2e-tests, multi-tenant-tests, performance-tests, security-tests]
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all test artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./all-test-results

      - name: Generate deployment readiness report
        run: |
          echo "# ðŸš€ Deployment Readiness Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check test results
          echo "| Test Suite | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|------------|--------|" >> $GITHUB_STEP_SUMMARY
          
          # Unit/Integration Tests
          if [ "${{ needs.unit-integration-tests.result }}" == "success" ]; then
            echo "| Unit & Integration Tests | âœ… Passed |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| Unit & Integration Tests | âŒ Failed |" >> $GITHUB_STEP_SUMMARY
          fi
          
          # E2E Tests
          if [ "${{ needs.e2e-tests.result }}" == "success" ]; then
            echo "| End-to-End Tests | âœ… Passed |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| End-to-End Tests | âŒ Failed |" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Multi-tenant Tests
          if [ "${{ needs.multi-tenant-tests.result }}" == "success" ]; then
            echo "| Multi-Tenant Security Tests | âœ… Passed |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| Multi-Tenant Security Tests | âŒ Failed |" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Performance Tests
          if [ "${{ needs.performance-tests.result }}" == "success" ]; then
            echo "| Performance & Load Tests | âœ… Passed |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| Performance & Load Tests | âŒ Failed |" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Security Tests
          if [ "${{ needs.security-tests.result }}" == "success" ]; then
            echo "| Security Tests | âœ… Passed |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| Security Tests | âŒ Failed |" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Overall recommendation
          if [ "${{ needs.unit-integration-tests.result }}" == "success" ] && \
             [ "${{ needs.e2e-tests.result }}" == "success" ] && \
             [ "${{ needs.multi-tenant-tests.result }}" == "success" ] && \
             [ "${{ needs.performance-tests.result }}" == "success" ] && \
             [ "${{ needs.security-tests.result }}" == "success" ]; then
            echo "## âœ… **READY FOR DEPLOYMENT**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "All critical tests have passed. The system is ready for production deployment." >> $GITHUB_STEP_SUMMARY
          else
            echo "## âŒ **NOT READY FOR DEPLOYMENT**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "One or more critical tests have failed. Please review the failures before deploying." >> $GITHUB_STEP_SUMMARY
          fi

      - name: Create deployment readiness artifact
        run: |
          mkdir -p deployment-readiness
          cat << EOF > deployment-readiness/readiness-report.json
          {
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "overall_status": "${{ (needs.unit-integration-tests.result == 'success' && needs.e2e-tests.result == 'success' && needs.multi-tenant-tests.result == 'success' && needs.performance-tests.result == 'success' && needs.security-tests.result == 'success') && 'ready' || 'not_ready' }}",
            "test_results": {
              "unit_integration": "${{ needs.unit-integration-tests.result }}",
              "e2e": "${{ needs.e2e-tests.result }}",
              "multi_tenant": "${{ needs.multi-tenant-tests.result }}",
              "performance": "${{ needs.performance-tests.result }}",
              "security": "${{ needs.security-tests.result }}"
            },
            "recommended_for_deployment": ${{ (needs.unit-integration-tests.result == 'success' && needs.e2e-tests.result == 'success' && needs.multi-tenant-tests.result == 'success' && needs.performance-tests.result == 'success' && needs.security-tests.result == 'success') && 'true' || 'false' }}
          }
          EOF

      - name: Upload deployment readiness report
        uses: actions/upload-artifact@v4
        with:
          name: deployment-readiness-report
          path: deployment-readiness/

  # Notification on failure
  notify-on-failure:
    name: Notify on Test Failure
    runs-on: ubuntu-latest
    needs: [unit-integration-tests, e2e-tests, multi-tenant-tests, performance-tests, security-tests]
    if: failure() && github.ref == 'refs/heads/main'
    steps:
      - name: Send Slack notification
        if: env.SLACK_WEBHOOK_URL != null
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          curl -X POST -H 'Content-type: application/json' \
            --data '{"text":"ðŸš¨ E2E Integration Tests Failed on main branch\n\nWorkflow: ${{ github.workflow }}\nCommit: ${{ github.sha }}\nAuthor: ${{ github.actor }}\n\nPlease check the failed tests: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"}' \
            $SLACK_WEBHOOK_URL 